\chapter{Implementation of Highest Delivery Guarantee} \label{chap:implementation}
As elaborated in section \ref{section:semantics}, Apache Kafka and Apache Pulsar can support exactly-once semantics as the highest guarantee while on NATS Streaming, only at-least-once delivery semantics can be achieved. In order to analyze in more detail how the platforms achieve their highest level of delivery guarantee, especially exactly-once semantics, a small use case is implemented on all three platforms. Apart from providing insights into the internal workflow of the platforms, this can also serve as a reference for realizing the delivery guarantee on the platforms in production. 
\section{Overview}
For the realization of delivery guarantee, a simple use case of banking transactions is used. Transactional activities of customers are recorded as events and published to the ESP platform. These raw events are transformed and the values of all transactions are aggregated to generate the current account balance for each user. The overview of event flow and the main components in the implementation is showed in figure \ref{fig:impusecase}.

To simulate the incoming events from customers, an event generator is implemented. The generator reads events from a CSV file which is prepared in advanced with data of 1000 transactional events of 5 customers. The generator then publishes these events to an event stream named \emph{raw-event}. Moreover, the event generator also checkpoints the line number in the CSV file of the published event to another stream named \emph{reading-position} on the ESP platform. In this way, when the event generator restarts, it can retrieve this checkpoint and resume the reading on the source file at the right position. 

To transform raw event, a stream processor is implemented. This component will ingest data from \emph{raw-event} stream, extract and transform the transactional value based on the event type and publish this transformed event back into another stream \emph{transformed-event}. This component will rely on the built-in mechanism of the ESP platform to manage the reading position on the \emph{raw-event} stream.



\begin{figure}
\begin{adjustwidth}{-1cm}{}
	\centering
	\includegraphics[width=18cm,height=\textheight]{images/implementation-use-case-1.png}
	
\end{adjustwidth}
\caption{Use case to implement delivery guarantee on the platforms.}
\label{fig:impusecase}
\end{figure}


Finally at the end of the event streams pipeline, the view generator component will accumulate the transactional values of each user and persist the resulted current balance to a PostgreSQL relational database. In addition, the view generator also commit the corresponding reading position on the source stream \emph{transformed-event} to the database so that it can fetch this value and resume the consumption on the stream accordingly upon restarting.


With this setup, message duplication can be easily detected because any transactional event which is processed more than once by any of the three processing components will result in different final current balances. To verify that the configuration and implementation is correct on each platform to achieve the highest message delivery guarantee, different failure scenarios are setup. The final current balances in these scenarios will be verified against the result from the reference scenario without failure.

 
\subsection{Failure scenarios}  \label{subsection:failurescenarios}
To focus on the components which interact directly with the platform, the source CSV file with events data and the relational database are assumed to be reliable with no failure. Moreover, the platforms are configured to be fault-tolerant with redundancies and assumed to be resilient to failures.  Failure scenarios will only be derived for three components: event generator, stream processor, and view generator.

\begin{figure}[h]
	\centering
	\includegraphics[width=8cm]{images/reading-position-fail.png}
	\caption{Failure scenarios \emph{event-generator-crash}, \emph{stream-processor-crash} and \emph{view-generator-crash}.}
	\label{fig:scenarioreadingposition}
\end{figure}

These components all have the processing cycle of an event as read-modify-write. After writing the modified event, these components must successfully update the reading position on the source system. Otherwise, failure when updating reading position can lead to the case where the last processed message will be redelivered and reprocessed when the application restarts. Three failure scenarios, namely, \emph{event-generator-crash}, \emph{stream-processor-crash} and \emph{view-generator-crash}, are derived for three processing components. In each failure scenario, one processing component along the processing pipeline is deliberately terminated before it can checkpoint the reading position on the data source to simulate the application crash (figure \ref{fig:scenarioreadingposition}). After that, the processing component will be restarted to continue with its incomplete task.



Kafka and Pulsar support using the consumer group pattern to read a partitioned topic with multiple concurrent consumer instances (section \ref{section:patterns}). In this case, users have the option to rely on the failover mechanism of the consumer group to automatically manage and assign partitions of the topic to consumer instances in the same group. However, this can lead to the case same messages are sent and buffered on two different consumer instances when the platform transfer ownership of a partition from one consumer to another. Therefore, for Apache Kafka and Apache Pulsar, another failure scenario called \emph{duplicated-consumer} is setup.

On Kafka, whenever a consumer sends a pulling request for new messages from Kafka, it will be notified about partition reassignment event if there is any. In normal condition, when the partitions are redistributed among the consumers (e.g. when a new consumer joins the consumer group), before the new consumer is notified about its newly assigned partition, the previous owner of the partition always has the chance to gracefully give up the ownership on the partition by committing the offset number of processed messages \cite{kafkaconsumerimplement}. Kafka handles the coordination of this transition process transparently to users. Therefore, same messages will not be delivered to two different consumers in this case. 

However, ownership on a partition can be revoked before the owning consumer is notified. This is the case when the consumer is stalled for some reason (e.g. garbage collection pause, some messages take longer to process than expected) and fails to send new messages pulling request within the permitted interval. In this case, the consumer will be removed from the group by Kafka and its partition will be reassigned to another consumer in the group. As a result, the messages whose offset numbers have not been committed by old consumer will be redelivered to the new one leading to message duplication on two instances. This scenario can be simulated by simply pausing a consumer instance in the consumer group after it has pulled a new batch of messages and before it starts to process and commit offset for these messages until Kafka deems this consumer to be disconnected (figure \ref{fig:kafkascenario}). 
\newpage
\begin{figure}[h]
	\centering
	\includegraphics[width=12cm]{images/kafka-duplicated-scenario.png}
	\caption{Failure scenario \emph{duplicated-consumer} on Kafka when a partition is reassigned without notifying the previous owning consumer.}
	\label{fig:kafkascenario}
\end{figure}

\iffalse

\begin{figure}[t!]
	\begin{adjustwidth}{-2cm}{-2cm}
	\centering

	\begin{subfigure}[t]{0.49\linewidth}
		\centering
		\includegraphics[width=\linewidth]{images/kafka-duplicated-scenario.png}
		\caption{Failure scenario \emph{duplicated-consumer} on Kafka when a partition is reassigned without notifying the previous owning consumer.}
		\label{fig:kafkascenario1}
	\end{subfigure}
	\begin{subfigure}[t]{0.49\linewidth}
		\centering
		\includegraphics[width=\linewidth]{images/pulsar-duplicated-scenario.png}
		\caption{Failure scenario \emph{duplicated-consumer} on Pulsar when a new consumer joins the failover subscription.}
		\label{fig:pulsarscenario1}
	\end{subfigure}
\end{adjustwidth}
	\caption{Failure scenario \emph{duplicated-consumer} on Kafka and Pulsar.}
	\label{fig:failurescenario}
\end{figure}
\fi
The failure scenario \emph{duplicated-consumer} can also occur with Pulsar. When a consumer subscribe to a Pulsar topic, messages on all topic assigned to this consumer will be pushed to a local queue until this queue is full \cite{pulsarbinaryprotocol}. When the consumer has consumed and acknowledged half of the buffered messages, new messages will be delivered. When a new consumer joins the same failover subscription, Pulsar broker will assign some topic partitions to it for load balancing. In this case, if the old consumer has not processed and acknowledged all messages of the reassigned partition on its queue, these messages will be redelivered again to the new consumer which causes message duplication on the queues of two consumers. This scenario can be provoked by introduced a small delay into the first consumer instance before it can start to process the messages on its local queue to give the second consumer instance enough time to join the subscription and receive the unprocessed messages again. This is illustrated in figure \ref{fig:pulsarscenario}.

\begin{figure}[h]
	\centering
	\includegraphics[width=12cm]{images/pulsar-duplicated-scenario.png}
	\caption{Failure scenario \emph{duplicated-consumer} on Pulsar when a new consumer joins the failover subscription.}
	\label{fig:pulsarscenario}
\end{figure}

The \emph{duplicated-consumer} scenario will be realized on the stream processor component where the consuming and producing of messages are done within the protection scope of the platform. For the view generator component which reads input from the ESP platform and writes output data to an external data sink, in order to have exactly-once semantics with this scenario, the gap between the platform and the data sink varies and must be bridged differently with different types of external system.

Table \ref{fig:failurescenariostable} gives a summary of the 4 failure scenarios and which processing component fails in each scenario.

\begin{table}[h!]
	\begin{adjustwidth}{-1cm}{}
	\centering
	\begin{tabular}{|l|l|l|l|}
		\hline
		& Event generator                                                          & Stream processor                                                                                                                        & View generator                                                           \\ \hline
		\textit{event-generator-crash}  & \begin{tabular}[t]{@{}l@{}}one instance\\ crash and restart\end{tabular} & \begin{tabular}[t]{@{}l@{}}one instance \\ no failure\end{tabular}                                                                      & \begin{tabular}[t]{@{}l@{}}one instance\\ no failure\end{tabular}        \\ \hline
		\textit{stream-processor-crash} & \begin{tabular}[t]{@{}l@{}}one instance\\ no failure\end{tabular}        & \begin{tabular}[t]{@{}l@{}}one instance\\ crash and restart\end{tabular}                                                                & \begin{tabular}[t]{@{}l@{}}one instance\\ no failure\end{tabular}        \\ \hline
		\textit{view-generator-crash}   & \begin{tabular}[t]{@{}l@{}}one instance\\ no failure\end{tabular}        & \begin{tabular}[t]{@{}l@{}}one instance\\ no failure\end{tabular}                                                                       & \begin{tabular}[t]{@{}l@{}}one instance\\ crash and restart\end{tabular} \\ \hline
		\textit{\begin{tabular}[t]{@{}l@{}}duplicated-consumer\\ (Kafka and Pulsar only)\end{tabular}}   & \begin{tabular}[t]{@{}l@{}}one instance\\ no failure\end{tabular}        & \begin{tabular}[t]{@{}l@{}}two instances \\ first instance: is delayed\\ second instance: no failure \end{tabular} & \begin{tabular}[t]{@{}l@{}}one instance\\ no failure\end{tabular}        \\ \hline
	\end{tabular}
	\end{adjustwidth}
	\caption{Summary of 4 failure scenarios.}
	\label{fig:failurescenariostable}
\end{table}

\input{chapters/implementation/implementation}
\input{chapters/implementation/result}